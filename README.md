# Songs Semantic Analysis Framework
This framework computes semantic similarity matrices of songs over years using multiple methods and models.

## Dataset Preparation Overview

Before running the semantic analysis, your dataset must include structured song metadata and lyrics.  
Additional semantic fields—such as topics, lyric segments, and normalized text—can be:

- Automatically generated using the provided preprocessing notebook  
- Manually curated and added by the user  

## Automatic Pre-processing Pipeline

The following notebook extracts topics, segments, and normalized text from raw lyrics:

**Songs Pre-processing Notebook (Google Colab)**  
https://colab.research.google.com/drive/1xZpso5ChbBPlyt8gQw66fyvUVmIB_C89?usp=sharing

Running the notebook will enrich the dataset with:

- `topics`
- `segments`
- `normalized_text`


## Example Dataset Files

The repository provides ready-to-use examples demonstrating both dataset formats; **both examples contain fully synthetic (invented) data and are intended for illustrative and testing purposes only**.

### Raw dataset (without semantic enrichment)
```
example_files/songs_data_without_topics_segments_norm.json
```

This version contains only basic metadata and lyrics.

### Enriched dataset (after notebook processing)

```
example_files/songs_data_with_topics_segments_norm.json
```

This version includes automatically generated:

- topics
- lyric segments
- normalized text

These examples allow you to:

- Compare before/after preprocessing
- Manually edit or extend semantic annotations


## Songs JSON Format
The dataset should be structured as a dictionary where **each key is a year** (as a string), and the value is a list of song entries for that year. Each song entry is a dictionary with the following fields:

| Key | Type | Description |
|-----|------|-------------|
| `song` | string | Full song name including performer(s) (e.g., `"Marco Verdi - Oltre il muro"`). |
| `text` | string | Full original lyrics of the song. |
| `title` | string | Song title only. |
| `authors` | string | Names of the authors/composers. |
| `performers` | string | Names of the performers. |
| `normalized_text` | string | Normalized or lemmatized lyrics (generated by the notebook). |
| `segments` | list of strings | Lyric segments or lines split for easier processing (generated by the notebook). |
| `topics` | list of objects | Extracted thematic labels containing `topic_title` and `reference_lyrics` (generated by the notebook). |

### Example
```json
{
  "2010": [
    {
      "song": "Marco Verdi - Oltre il muro",
      "title": "Oltre il muro",
      "authors": "Marco Verdi - Giulia Bianchi",
      "performers": "Marco Verdi",
      "text": "Le strade si perdono tra i palazzi di vetro\ncerco un motivo per non tornare indietro...",
      "topics": [
        {
          "topic_title": "Amore e separazione",
          "reference_lyrics": "cerco un motivo per non tornare indietro, le parole che non ti ho mai detto davvero"
        },
        {
          "topic_title": "Dolore e nostalgia",
          "reference_lyrics": "il dolore, il sapore di un bacio rubato in un giorno di pioggia"
        }
      ],
      "segments": [
        "Le strade si perdono tra i palazzi di vetro\ncerco un motivo per non tornare indietro",
        "il rumore del traffico è un battito lento\nche cancella ogni mio sentimento."
      ],
      "normalized_text": "le strade si perdono tra il palazzo di vetro\ncerco un motivo per non tornare indietro..."
    }
  ],
  "2011": [
    {
      "song": "Luca G. - Cielo di pioggia",
      "title": "Cielo di pioggia",
      "authors": "Luca G. - Sara Neri",
      "performers": "Luca G.",
      "text": "Le nuvole basse coprono i tetti...",
      "topics": [
        {
          "topic_title": "Natura e condizioni climatiche",
          "reference_lyrics": "Le nuvole basse coprono i tetti nascondono tutti i nostri difetti"
        }
      ],
      "segments": [
        "Le nuvole basse coprono i tetti nascondono tutti i nostri difetti",
        "respiro l'odore della terra bagnata in questa mattina così complicata."
      ],
      "normalized_text": "le nuvola bassa copre il tetto\nnasconde il nostro difetto..."
    }
  ]
}
```

## Credentials JSON Format

The framework requires a JSON file containing the credentials needed to run the repository.

### Mandatory Credentials

A **Hugging Face token (`hf_token`) is required** in order to run the framework, as it is used to load embedding models and other core components.

```json
{
  "hf_token": "YOUR_HUGGINGFACE_TOKEN"
}
```
### Optional OpenAI / Azure OpenAI Credentials

OpenAI credentials are **optional** and are only required if you want to enable semantic similarity computations based on OpenAI models.

#### Standard OpenAI configuration
```json
{
  "hf_token": "YOUR_HUGGINGFACE_TOKEN",
  "openai": {
    "api_key": "YOUR_OPENAI_API_KEY"
  }
}
```

#### Azure OpenAI configuration

```json
{
  "hf_token": "YOUR_HUGGINGFACE_TOKEN",
  "openai": {
    "api_key": "YOUR_API_KEY",
    "api_version": "2024-06-01",
    "azure_endpoint": "https://your-custom-endpoint.openai.azure.com/"
  }
}
```

## Running the Similarity Matrix Computation

The computation of **pairwise semantic similarity matrices across years** can be performed by running the dedicated script from the command line.
Therefore, you should use the enriched JSON file generated by the preprocessing notebook (e.g., `example_files/songs_data_with_topics_segments_norm.json`), or a manually curated JSON containing the same fields.


### Command-line execution

```bash
python compute_matrices.py \
  --songs_file "{songs_json}" \
  --credentials "{credentials_json}"
```

Where:  
- `{songs_json}` is the path to the songs dataset JSON file (raw or enriched)  
- `{credentials_json}` is the path to the credentials JSON file containing at least the mandatory `hf_token`  

The script will compute **pairwise semantic similarity matrices** according to the models and methods enabled by the provided credentials.


### Testing with Google Colab

For quick testing and experimentation, you can also run the pipeline to compute the final matrices and correlation figures using the provided Google Colab notebook:

**Songs Similarity Computation Notebook (Google Colab)**  
https://colab.research.google.com/drive/1K7bn0m59SdZK-IbEk77wl__PULTvfmZu?usp=sharing
